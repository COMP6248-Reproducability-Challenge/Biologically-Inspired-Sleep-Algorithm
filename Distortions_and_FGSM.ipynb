{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Distortions and FGSM.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "033449bd370345e1aa8e6dc96ad03b79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_1e585cc3a94f4297b9c787511c88ee55",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_abd2fce3b31440e89c73790e607d53eb",
              "IPY_MODEL_b157c15c78d74ab682c64b5523d2d143"
            ]
          }
        },
        "1e585cc3a94f4297b9c787511c88ee55": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "abd2fce3b31440e89c73790e607d53eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_da576561247248329e4a5fa881ddcde3",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 9912422,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 9912422,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4297ec56faf043e7a12045a948e73439"
          }
        },
        "b157c15c78d74ab682c64b5523d2d143": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_6fae8573b0ec4f98946b405ad454a97b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 9913344/? [03:37&lt;00:00, 63762.23it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6deb1388a058427481499d46602b403e"
          }
        },
        "da576561247248329e4a5fa881ddcde3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4297ec56faf043e7a12045a948e73439": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6fae8573b0ec4f98946b405ad454a97b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6deb1388a058427481499d46602b403e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DuckShyamalan/COMP6248-Reproducibility-Challenge/blob/main/Distortions_and_FGSM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZlPlHpHTSduG",
        "outputId": "11eca49e-cfa0-46b6-b221-2baa26a94fb7"
      },
      "source": [
        "# Execute this code block to install dependencies when running on colab\n",
        "try:\n",
        "    import torch\n",
        "except:\n",
        "    from os.path import exists\n",
        "    from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "    platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "    cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n",
        "    accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n",
        "\n",
        "    !pip install -q http://download.pytorch.org/whl/{accelerator}/torch-1.0.0-{platform}-linux_x86_64.whl torchvision\n",
        "\n",
        "try: \n",
        "    import torchbearer\n",
        "except:\n",
        "    !pip install torchbearer"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torchbearer\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ff/e9/4049a47dd2e5b6346a2c5d215b0c67dce814afbab1cd54ce024533c4834e/torchbearer-0.5.3-py3-none-any.whl (138kB)\n",
            "\r\u001b[K     |██▍                             | 10kB 16.7MB/s eta 0:00:01\r\u001b[K     |████▊                           | 20kB 22.4MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 30kB 12.4MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 40kB 9.6MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 51kB 5.1MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 61kB 5.4MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 71kB 5.8MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 81kB 6.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 92kB 6.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 102kB 6.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 112kB 6.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 122kB 6.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 133kB 6.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 143kB 6.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchbearer) (1.19.5)\n",
            "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from torchbearer) (1.8.1+cu101)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torchbearer) (4.41.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.0.0->torchbearer) (3.7.4.3)\n",
            "Installing collected packages: torchbearer\n",
            "Successfully installed torchbearer-0.5.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-xPeofkDXYVk"
      },
      "source": [
        "import torch\n",
        "import torchbearer\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import MNIST\n",
        "from scipy.ndimage import gaussian_filter\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KGRop3D5XmRL"
      },
      "source": [
        "# fix random seed for reproducibility\n",
        "seed = 7\n",
        "torch.manual_seed(seed)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "np.random.seed(seed)\n",
        "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\""
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OWmXVQQYXqbF"
      },
      "source": [
        "# flatten 28*28 images to a 784 vector for each image\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),  # convert to tensor\n",
        "    transforms.Lambda(lambda x: x.view(-1))  # flatten into vector\n",
        "])"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PLvciLwHnzLe"
      },
      "source": [
        "#403 fix\n",
        "from six.moves import urllib\n",
        "opener = urllib.request.build_opener()\n",
        "opener.addheaders = [('User-agent', 'Mozilla/5.0')]\n",
        "urllib.request.install_opener(opener)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103,
          "referenced_widgets": [
            "033449bd370345e1aa8e6dc96ad03b79",
            "1e585cc3a94f4297b9c787511c88ee55",
            "abd2fce3b31440e89c73790e607d53eb",
            "b157c15c78d74ab682c64b5523d2d143",
            "da576561247248329e4a5fa881ddcde3",
            "4297ec56faf043e7a12045a948e73439",
            "6fae8573b0ec4f98946b405ad454a97b",
            "6deb1388a058427481499d46602b403e"
          ]
        },
        "id": "WqukxX49d1pQ",
        "outputId": "1df28bee-0520-44d9-9d8b-0cfd3c6346ab"
      },
      "source": [
        "trainset = MNIST(\".\", train=True, download=True, transform=transform)\n",
        "testset = MNIST(\".\", train=False, download=True, transform=transform)\n",
        "\n",
        "trainset.data = trainset.data[0:27105]\n",
        "trainset.targets = trainset.targets[0:27105]\n",
        "\n",
        "# create data loaders\n",
        "trainloader = DataLoader(trainset, batch_size=128, shuffle=True)\n",
        "testloader = DataLoader(testset, batch_size=128, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./MNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "033449bd370345e1aa8e6dc96ad03b79",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=9912422.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6_0IcPomdi-w"
      },
      "source": [
        "### Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "PjXtaOt8XtTG",
        "outputId": "620c0931-5e39-4587-c48b-6a5cb3622725"
      },
      "source": [
        "#Baseline\n",
        "class BaselineModel(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, num_classes):\n",
        "    super(BaselineModel, self).__init__()\n",
        "    self.fc1 = nn.Linear(input_size, hidden_size) \n",
        "    self.fc2 = nn.Linear(hidden_size, hidden_size) \n",
        "    self.fc3 = nn.Linear(hidden_size, num_classes)  \n",
        "    \n",
        "  def forward(self, x):\n",
        "      out = self.fc1(x)\n",
        "      out = F.relu(out)\n",
        "      out = F.dropout(out, 0.2)        \n",
        "      out = self.fc2(out)        \n",
        "      out = F.relu(out)\n",
        "      out = self.fc3(out)\n",
        "      if not self.training:\n",
        "          out = F.softmax(out, dim=1)\n",
        "      return out\n",
        "\n",
        "#Defensive Distillation\n",
        "class DistillationNetwork(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(DistillationNetwork, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(1, 32, (5, 5), padding=0)\n",
        "    self.conv2 = nn.Conv2d(32, 64, (3, 3), padding=0)\n",
        "    self.fc1 = nn.Linear(64 * 5**2, 1200)\n",
        "    self.fc2 = nn.Linear(1200, 10)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = torch.reshape(x, [-1, 1,28,28])  #need x to be a 4-d input instead of 2-d\n",
        "    out = self.conv1(x)\n",
        "    out = F.relu(out)\n",
        "    out = F.max_pool2d(out, (2,2))\n",
        "    out = self.conv2(out)\n",
        "    out = F.relu(out)\n",
        "    out = F.max_pool2d(out, (2,2))\n",
        "    out = F.dropout(out, 0.2)\n",
        "    out = out.view(out.shape[0], -1)\n",
        "    out = self.fc1(out)\n",
        "    out = F.relu(out)\n",
        "    out = self.fc2(out)\n",
        "    if not self.training:\n",
        "      out = F.softmax(out/50, dim=1)  #authors used T=50\n",
        "    return out\n",
        "\n",
        "#Fine-tuning\n",
        "class FineTuneModel(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, num_classes):\n",
        "    super(FineTuneModel, self).__init__()\n",
        "    self.fc1 = nn.Linear(input_size, hidden_size) \n",
        "    self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
        "    self.fc3 = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "  def forward(self, x):\n",
        "    out = self.fc1(x)\n",
        "    out = F.relu(out)\n",
        "    out = F.dropout(out, 0.2)\n",
        "    out = self.fc2(out)\n",
        "    out = F.relu(out)\n",
        "    out = self.fc3(out)\n",
        "    if not self.training:\n",
        "      out = F.softmax(out, dim=1)\n",
        "    return out\n",
        "\n",
        "#Control ANN?\n",
        "'''TODO: \n",
        "check fine-tuning learning rate; \n",
        "crosscheck if controlANN is required considering it seems to be the same as FineTuneModel\n",
        "''' \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'TODO: \\ncheck fine-tuning learning rate; \\ncrosscheck if controlANN is required considering it seems to be the same as FineTuneModel\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mFDEZlRrb-1F"
      },
      "source": [
        "#Fast Gradient Sign Method (FGSM) for generating adversarial images\n",
        "def fgsm(model, lossfn, images, labels, eps):\n",
        "  #x′ = x + εsign(∇xJ(θ,x,y))\n",
        "  \n",
        "  images = images.to(device)\n",
        "  labels = labels.to(device)\n",
        "  images.requires_grad = True\n",
        "\n",
        "  outputs = model(images)\n",
        "  model.zero_grad() #no optimiser\n",
        "\n",
        "  # forward + loss + backward + optimise (update weights)\n",
        "  loss = lossfn(outputs, labels).to(device)\n",
        "  loss.backward()\n",
        "\n",
        "  atk = torch.clamp(images + eps*images.grad.sign(), 0,1) #min value 0; max 1\n",
        "  return atk"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c5K2v_EhdpPN"
      },
      "source": [
        "# **Blur**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_K2eE_ccjtd"
      },
      "source": [
        "blur_sigma = [0, 0.5, 1.0, 1.5, 2.0, 2.5]\n",
        "\n",
        "#lists containing test accuracies\n",
        "blur_control = []\n",
        "blur_sleep = []\n",
        "blur_ftblur = []\n",
        "blur_ftnoise = []\n",
        "blur_defdist = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_lKy8ZhpdXR"
      },
      "source": [
        "for s in blur_sigma:\n",
        "  #blur data\n",
        "  trainset = MNIST(\".\", train=True, download=True, transform=transform)\n",
        "  testset = MNIST(\".\", train=False, download=True, transform=transform)\n",
        "\n",
        "  trainset.data = trainset.data[0:27105]\n",
        "  trainset.targets = trainset.targets[0:27105]\n",
        "\n",
        "  trainloader = DataLoader(trainset, batch_size=128, shuffle=True)\n",
        "  testloader = DataLoader(testset, batch_size=128, shuffle=True)\n",
        "\n",
        "  #distorting the testset\n",
        "  for i in range(0, len(testset)):\n",
        "    img = testset.test_data[i].numpy()\n",
        "    blurred_img = gaussian_filter(img, sigma=s)\n",
        "    testset.test_data[i] = torch.from_numpy(blurred_img)\n",
        "\n",
        "  trainloader = DataLoader(trainset, batch_size=128, shuffle=True)\n",
        "  testloader = DataLoader(testset, batch_size=128, shuffle=True)\n",
        "\n",
        "\n",
        "  #test the control network\n",
        "  #model = torch.load('save_ann.pkl')  #baseline ann\n",
        "  model = BaselineModel(784, 1200, 10)\n",
        "  model.load_state_dict(torch.load(\"Models/fine_tune.pt\"))  #baseline ann\n",
        "  loss_function = nn.CrossEntropyLoss()\n",
        "  optimiser = optim.SGD(model.parameters(), lr=0.1, momentum=0.5)\n",
        "  trial = torchbearer.Trial(model, optimiser, loss_function, metrics=['loss', 'accuracy']).to(device)\n",
        "  trial.with_generators(trainloader, test_generator=testloader)\n",
        "  #trial.run(epochs=2)\n",
        "  results = trial.evaluate(data_key=torchbearer.TEST_DATA)\n",
        "  blur_control.append(results[\"test_acc\"])\n",
        "\n",
        "  #test the sleep network\n",
        "  #model = torch.load('save_sleep.pkl')  #sleep\n",
        "  model = FineTuneModel(784, 1200, 10)\n",
        "  model.load_state_dict(torch.load(\"Models/sleep.pt\"))  #sleep\n",
        "  loss_function = nn.CrossEntropyLoss()\n",
        "  optimiser = optim.SGD(model.parameters(), lr=0.1, momentum=0.5)\n",
        "  trial = torchbearer.Trial(model, optimiser, loss_function, metrics=['loss', 'accuracy']).to(device)\n",
        "  trial.with_generators(trainloader, test_generator=testloader)\n",
        "  #trial.run(epochs=2)\n",
        "  results = trial.evaluate(data_key=torchbearer.TEST_DATA)\n",
        "  blur_sleep.append(results[\"test_acc\"])\n",
        "\n",
        "  #test the finetuned network with blur\n",
        "  #model = torch.load('save_blur.pkl')  #sleep\n",
        "  model = FineTuneModel(784, 1200, 10)\n",
        "  model.load_state_dict(torch.load(\"Models/blur_model.pt\"))  #sleep\n",
        "  loss_function = nn.CrossEntropyLoss()\n",
        "  optimiser = optim.SGD(model.parameters(), lr=0.1, momentum=0.5)\n",
        "  trial = torchbearer.Trial(model, optimiser, loss_function, metrics=['loss', 'accuracy']).to(device)\n",
        "  trial.with_generators(trainloader, test_generator=testloader)\n",
        "  #trial.run(epochs=2)\n",
        "  results = trial.evaluate(data_key=torchbearer.TEST_DATA)\n",
        "  blur_ftblur.append(results[\"test_acc\"])\n",
        "\n",
        "  #test the finetuned network with noise\n",
        "  #model = torch.load('save_blur.pkl')  #sleep\n",
        "  model = FineTuneModel(784, 1200, 10)\n",
        "  model.load_state_dict(torch.load(\"Models/noise_model.pt\"))  #sleep\n",
        "  loss_function = nn.CrossEntropyLoss()\n",
        "  optimiser = optim.SGD(model.parameters(), lr=0.1, momentum=0.5)\n",
        "  trial = torchbearer.Trial(model, optimiser, loss_function, metrics=['loss', 'accuracy']).to(device)\n",
        "  trial.with_generators(trainloader, test_generator=testloader)\n",
        "  #trial.run(epochs=2)\n",
        "  results = trial.evaluate(data_key=torchbearer.TEST_DATA)\n",
        "  blur_ftnoise.append(results[\"test_acc\"])\n",
        "\n",
        "  #test the defensive distillation network\n",
        "  model = DistillationNetwork()\n",
        "  model.load_state_dict(torch.load(\"Models/def_distil_model.pt\"))\n",
        "  loss_function = nn.CrossEntropyLoss()\n",
        "  optimiser = optim.SGD(model.parameters(), lr=0.1, momentum=0.5)\n",
        "  trial = torchbearer.Trial(model, optimiser, loss_function, metrics=['loss', 'accuracy']).to(device)\n",
        "  trial.with_generators(trainloader, test_generator=testloader)\n",
        "  #trial.run(epochs=2)\n",
        "  results = trial.evaluate(data_key=torchbearer.TEST_DATA)\n",
        "  blur_defdist.append(results[\"test_acc\"])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BXZFT_jP9ro9"
      },
      "source": [
        "fig = plt.figure(figsize=(8,5))\n",
        "fig.suptitle('Blurry Data Accuracies', fontsize=16)\n",
        "ax = fig.add_subplot(111)\n",
        "ax.plot(blur_sigma, [i*100 for i in blur_control, color=\"red\", label=\"Control Model\")\n",
        "ax.plot(blur_sigma,[i*100 for i in blur_sleep, color='dodgerblue', label=\"Sleep Model\")\n",
        "ax.plot(blur_sigma,[i*100 for i in blur_ftblur, color=\"limegreen\", label=\"Fine-tuned Blurred Model\")\n",
        "ax.plot(blur_sigma,[i*100 for i in blur_ftnoise, color=\"darkorange\", label=\"Fine-tuned Noise Model\")\n",
        "ax.plot(blur_sigma,[i*100 for i in blur_defdist, color='m', label=\"Defensive Distillation Model\")\n",
        "ax.set_xlabel(\"Standard Deviation\")\n",
        "ax.set_ylabel(\"Accuracy\")\n",
        "ax.set_xlim(xmin=0.0, xmax=15)\n",
        "ax.legend(loc=\"upper right\", bbox_to_anchor=(1.4, 1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lD7MNkan9anZ"
      },
      "source": [
        "# **Noise**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yXU-fpmxyHd7"
      },
      "source": [
        "noise_variance = [0, 0.2, 0.4, 0.6, 0.8, 1.0]\n",
        "\n",
        "#lists containing test accuracies\n",
        "noise_control = []\n",
        "noise_sleep = []\n",
        "noise_ftblur = []\n",
        "noise_ftnoise = []\n",
        "noise_defdist = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "26aHnSHnxz6M"
      },
      "source": [
        "for v in noise_variance:\n",
        "  #add noise to data\n",
        "  trainset = MNIST(\".\", train=True, download=True, transform=transform)\n",
        "  testset = MNIST(\".\", train=False, download=True, transform=transform)\n",
        "\n",
        "  trainset.data = trainset.data[0:27105]\n",
        "  trainset.targets = trainset.targets[0:27105]\n",
        "\n",
        "  trainloader = DataLoader(trainset, batch_size=128, shuffle=True)\n",
        "  testloader = DataLoader(testset, batch_size=128, shuffle=True)\n",
        "\n",
        "  #distorting the testset\n",
        "  for i in range(0, len(testset)):\n",
        "    img = testset.test_data[i].numpy()\n",
        "    noise = np.random.normal(0, np.sqrt(v), img.shape)\n",
        "    noisy_img = img + noise\n",
        "    testset.test_data[i] = torch.from_numpy(noisy_img)\n",
        "\n",
        "  trainloader = DataLoader(trainset, batch_size=128, shuffle=True)\n",
        "  testloader = DataLoader(testset, batch_size=128, shuffle=True)\n",
        "\n",
        "\n",
        "  #test the control network\n",
        "  #model = torch.load('save_ann.pkl')  #baseline ann\n",
        "  model = BaselineModel(784, 1200, 10)\n",
        "  model.load_state_dict(torch.load(\"Models/fine_tune.pt\"))  #baseline ann\n",
        "  loss_function = nn.CrossEntropyLoss()\n",
        "  optimiser = optim.SGD(model.parameters(), lr=0.1, momentum=0.5)\n",
        "  trial = torchbearer.Trial(model, optimiser, loss_function, metrics=['loss', 'accuracy']).to(device)\n",
        "  trial.with_generators(trainloader, test_generator=testloader)\n",
        "  #trial.run(epochs=2)\n",
        "  results = trial.evaluate(data_key=torchbearer.TEST_DATA)\n",
        "  blur_control.append(results[\"test_acc\"])\n",
        "\n",
        "  #test the sleep network\n",
        "  #model = torch.load('save_sleep.pkl')  #sleep\n",
        "  model = FineTuneModel(784, 1200, 10)\n",
        "  model.load_state_dict(torch.load(\"Models/sleep.pt\"))  #sleep\n",
        "  loss_function = nn.CrossEntropyLoss()\n",
        "  optimiser = optim.SGD(model.parameters(), lr=0.1, momentum=0.5)\n",
        "  trial = torchbearer.Trial(model, optimiser, loss_function, metrics=['loss', 'accuracy']).to(device)\n",
        "  trial.with_generators(trainloader, test_generator=testloader)\n",
        "  #trial.run(epochs=2)\n",
        "  results = trial.evaluate(data_key=torchbearer.TEST_DATA)\n",
        "  blur_sleep.append(results[\"test_acc\"])\n",
        "\n",
        "  #test the finetuned network with blur\n",
        "  #model = torch.load('save_blur.pkl')  #sleep\n",
        "  model = FineTuneModel(784, 1200, 10)\n",
        "  model.load_state_dict(torch.load(\"Models/blur_model.pt\"))  #sleep\n",
        "  loss_function = nn.CrossEntropyLoss()\n",
        "  optimiser = optim.SGD(model.parameters(), lr=0.1, momentum=0.5)\n",
        "  trial = torchbearer.Trial(model, optimiser, loss_function, metrics=['loss', 'accuracy']).to(device)\n",
        "  trial.with_generators(trainloader, test_generator=testloader)\n",
        "  #trial.run(epochs=2)\n",
        "  results = trial.evaluate(data_key=torchbearer.TEST_DATA)\n",
        "  blur_ftblur.append(results[\"test_acc\"])\n",
        "\n",
        "  #test the finetuned network with noise\n",
        "  #model = torch.load('save_blur.pkl')  #sleep\n",
        "  model = FineTuneModel(784, 1200, 10)\n",
        "  model.load_state_dict(torch.load(\"Models/noise_model.pt\"))  #sleep\n",
        "  loss_function = nn.CrossEntropyLoss()\n",
        "  optimiser = optim.SGD(model.parameters(), lr=0.1, momentum=0.5)\n",
        "  trial = torchbearer.Trial(model, optimiser, loss_function, metrics=['loss', 'accuracy']).to(device)\n",
        "  trial.with_generators(trainloader, test_generator=testloader)\n",
        "  #trial.run(epochs=2)\n",
        "  results = trial.evaluate(data_key=torchbearer.TEST_DATA)\n",
        "  blur_ftnoise.append(results[\"test_acc\"])\n",
        "\n",
        "  #test the defensive distillation network\n",
        "  model = DistillationNetwork()\n",
        "  model.load_state_dict(torch.load(\"Models/def_distil_model.pt\"))\n",
        "  loss_function = nn.CrossEntropyLoss()\n",
        "  optimiser = optim.SGD(model.parameters(), lr=0.1, momentum=0.5)\n",
        "  trial = torchbearer.Trial(model, optimiser, loss_function, metrics=['loss', 'accuracy']).to(device)\n",
        "  trial.with_generators(trainloader, test_generator=testloader)\n",
        "  #trial.run(epochs=2)\n",
        "  results = trial.evaluate(data_key=torchbearer.TEST_DATA)\n",
        "  blur_defdist.append(results[\"test_acc\"])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0t7FmjxP0KwX"
      },
      "source": [
        "fig = plt.figure(figsize=(8,5))\n",
        "fig.suptitle('Noisy Data Accuracies', fontsize=16)\n",
        "ax = fig.add_subplot(111)\n",
        "ax.plot([i*100 for i in noise_control, color=\"red\", label=\"Control Model\")\n",
        "ax.plot([i*100 for i in noise_sleep, color='dodgerblue', label=\"Sleep Model\")\n",
        "ax.plot([i*100 for i in noise_ftblur, color=\"limegreen\", label=\"Fine-tuned Blurred Model\")\n",
        "ax.plot([i*100 for i in noise_ftnoise, color=\"darkorange\", label=\"Fine-tuned Noise Model\")\n",
        "ax.plot([i*100 for i in noise_defdist, color='m', label=\"Defensive Distillation Model\")\n",
        "ax.set_xlabel(\"Variance\")\n",
        "ax.set_ylabel(\"Accuracy\")\n",
        "ax.set_xlim(xmin=0.0, xmax=15)\n",
        "ax.legend(loc=\"upper right\", bbox_to_anchor=(1.4, 1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOP5oAzU0LvE"
      },
      "source": [
        "# **FGSM**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wQ5URstM0K-U"
      },
      "source": [
        "epsilons = [0, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4]\n",
        "\n",
        "#lists containing test accuracies\n",
        "fgsm_control = []\n",
        "fgsm_sleep = []\n",
        "fgsm_ftblur = []\n",
        "fgsm_ftnoise = []\n",
        "fgsm_defdist = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sgl9oAJM06CG"
      },
      "source": [
        "for eps in epsilons:\n",
        "  #FGSM\n",
        "  trainset = MNIST(\".\", train=True, download=True, transform=transform)\n",
        "  testset = MNIST(\".\", train=False, download=True, transform=transform)\n",
        "  trainset.data = trainset.data[0:27105]\n",
        "  trainset.targets = trainset.targets[0:27105]\n",
        "\n",
        "  trainloader = DataLoader(trainset, batch_size=128, shuffle=True)\n",
        "  testloader = DataLoader(testset, batch_size=128, shuffle=True)\n",
        "\n",
        "  trainloader = DataLoader(trainset, batch_size=128, shuffle=True)\n",
        "  testloader = DataLoader(testset, batch_size=128, shuffle=True)\n",
        "\n",
        "  #FGSM on the baseline model\n",
        "  #model = torch.load('save_ann.pkl') #baseline\n",
        "  model = BaselineModel(784, 1200, 10)\n",
        "  model.load_state_dict(torch.load('Models/save_ann.pt')) #baseline\n",
        "  model.eval()\n",
        "  loss_function = nn.CrossEntropyLoss()\n",
        "  correct = 0.0\n",
        "  total = 0.0\n",
        "  for data in testloader:\n",
        "    inputs, labels = data\n",
        "    inputs = fgsm_attack(model, loss_function, inputs, labels, eps).to(device)\n",
        "    labels = labels.to(device)\n",
        "    outputs = model(inputs)\n",
        "    \n",
        "    max_prob = torch.argmax(outputs, dim=1)\n",
        "    temp = max_prob == labels\n",
        "    correct += [i for i in temp if i == True]\n",
        "    total += len(labels)\n",
        "\n",
        "  acc = correct/total\n",
        "  print(\"Accuracy of the testset: \", acc)\n",
        "  fgsm_control.append(acc)\n",
        "\n",
        "  #FGSM on the sleep network\n",
        "  #model = torch.load('save_sleep.pkl') #sleep\n",
        "  model = FineTuneModel(784, 1200, 10)\n",
        "  model.load_state_dict(torch.load('Models/save_sleep.pt')) #sleep\n",
        "  model.eval()\n",
        "  loss_function = nn.CrossEntropyLoss()\n",
        "  correct = 0.0\n",
        "  total = 0.0\n",
        "  for data in testloader:\n",
        "    inputs, labels = data\n",
        "    inputs = fgsm_attack(model, loss_function, inputs, labels, eps).to(device)\n",
        "    labels = labels.to(device)\n",
        "    outputs = model(inputs)\n",
        "    \n",
        "    max_prob = torch.argmax(outputs, dim=1)\n",
        "    temp = max_prob == labels\n",
        "    correct += [i for i in temp if i == True]\n",
        "    total += len(labels)\n",
        "\n",
        "  acc = correct/total\n",
        "  print(\"Accuracy of the testset: \", acc)\n",
        "  fgsm_sleep.append(acc)\n",
        "\n",
        "  #FGSM on the finetuned network with blur\n",
        "  #model = torch.load('save_blur.pkl') #blur\n",
        "  model = FineTuneModel(784, 1200, 10)\n",
        "  model.load_state_dict(torch.load('Models/blur_model.pt')) #blur\n",
        "  model.eval()\n",
        "  loss_function = nn.CrossEntropyLoss()\n",
        "  correct = 0.0\n",
        "  total = 0.0\n",
        "  for data in testloader:\n",
        "    inputs, labels = data\n",
        "    inputs = fgsm_attack(model, loss_function, inputs, labels, eps).to(device)\n",
        "    labels = labels.to(device)\n",
        "    outputs = model(inputs)\n",
        "    \n",
        "    max_prob = torch.argmax(outputs, dim=1)\n",
        "    temp = max_prob == labels\n",
        "    correct += [i for i in temp if i == True]\n",
        "    total += len(labels)\n",
        "\n",
        "  acc = correct/total\n",
        "  print(\"Accuracy of the testset: \", acc)\n",
        "  fgsm_ftblur.append(acc)\n",
        "\n",
        "  #FGSM on the finetuned network with noise\n",
        "  #model = torch.load('save_blur.pkl') #noise\n",
        "  model = FineTuneModel(784, 1200, 10)\n",
        "  model.load_state_dict(torch.load('Models/noise_model.pt')) #noise\n",
        "  model.eval()\n",
        "  loss_function = nn.CrossEntropyLoss()\n",
        "  correct = 0.0\n",
        "  total = 0.0\n",
        "  for data in testloader:\n",
        "    inputs, labels = data\n",
        "    inputs = fgsm_attack(model, loss_function, inputs, labels, eps).to(device)\n",
        "    labels = labels.to(device)\n",
        "    outputs = model(inputs)\n",
        "    \n",
        "    max_prob = torch.argmax(outputs, dim=1)\n",
        "    temp = max_prob == labels\n",
        "    correct += [i for i in temp if i == True]\n",
        "    total += len(labels)\n",
        "\n",
        "  acc = correct/total\n",
        "  print(\"Accuracy of the testset: \", acc)\n",
        "  fgsm_ftnoise.append(acc)\n",
        "\n",
        "  #FGSM on the defensive distillation network\n",
        "  #model = torch.load('save_blur.pkl') #def. dist.\n",
        "  model = FineTuneModel(784, 1200, 10)\n",
        "  model.load_state_dict(torch.load('Models/def_distil_model.pt')) #def. dist.\n",
        "  model.eval()\n",
        "  loss_function = nn.CrossEntropyLoss()\n",
        "  correct = 0.0\n",
        "  total = 0.0\n",
        "  for data in testloader:\n",
        "    inputs, labels = data\n",
        "    inputs = fgsm_attack(model, loss_function, inputs, labels, eps).to(device)\n",
        "    labels = labels.to(device)\n",
        "    outputs = model(inputs)\n",
        "    \n",
        "    max_prob = torch.argmax(outputs, dim=1)\n",
        "    temp = max_prob == labels\n",
        "    correct += [i for i in temp if i == True]\n",
        "    total += len(labels)\n",
        "\n",
        "  acc = correct/total\n",
        "  print(\"Accuracy of the testset: \", acc)\n",
        "  fgsm_defdist.append(acc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oWMMmIKU-x0S"
      },
      "source": [
        "fig = plt.figure(figsize=(8,5))\n",
        "fig.suptitle('FGSM Attack Accuracies', fontsize=16)\n",
        "ax = fig.add_subplot(111)\n",
        "ax.plot([i*100 for i in fgsm_control, color=\"red\", label=\"Control Model\")\n",
        "ax.plot([i*100 for i in fgsm_sleep, color='dodgerblue', label=\"Sleep Model\")\n",
        "ax.plot([i*100 for i in fgsm_ftblur, color=\"limegreen\", label=\"Fine-tuned Blurred Model\")\n",
        "ax.plot([i*100 for i in fgsm_ftnoise, color=\"darkorange\", label=\"Fine-tuned Noise Model\")\n",
        "ax.plot([i*100 for i in fgsm_defdist, color='m', label=\"Defensive Distillation Model\")\n",
        "ax.set_xlabel(\"Noise Level\")\n",
        "ax.set_ylabel(\"Accuracy\")\n",
        "ax.set_xlim(xmin=0.0, xmax=15)\n",
        "ax.legend(loc=\"upper right\", bbox_to_anchor=(1.4, 1))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}