{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Distortions and FGSM.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP2OaTFS2UutL6T+M2fpOpe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DuckShyamalan/COMP6248-Reproducibility-Challenge/blob/main/Distortions_and_FGSM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZlPlHpHTSduG",
        "outputId": "b95fc508-f8da-4cb6-d198-cd8b082e7ddf"
      },
      "source": [
        "# Execute this code block to install dependencies when running on colab\n",
        "try:\n",
        "    import torch\n",
        "except:\n",
        "    from os.path import exists\n",
        "    from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "    platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "    cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n",
        "    accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n",
        "\n",
        "    !pip install -q http://download.pytorch.org/whl/{accelerator}/torch-1.0.0-{platform}-linux_x86_64.whl torchvision\n",
        "\n",
        "try: \n",
        "    import torchbearer\n",
        "except:\n",
        "    !pip install torchbearer"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torchbearer\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ff/e9/4049a47dd2e5b6346a2c5d215b0c67dce814afbab1cd54ce024533c4834e/torchbearer-0.5.3-py3-none-any.whl (138kB)\n",
            "\r\u001b[K     |██▍                             | 10kB 15.4MB/s eta 0:00:01\r\u001b[K     |████▊                           | 20kB 20.4MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 30kB 10.6MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 40kB 8.8MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 51kB 5.0MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 61kB 5.8MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 71kB 5.6MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 81kB 5.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 92kB 6.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 102kB 6.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 112kB 6.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 122kB 6.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 133kB 6.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 143kB 6.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchbearer) (1.19.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torchbearer) (4.41.1)\n",
            "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from torchbearer) (1.8.1+cu101)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.0.0->torchbearer) (3.7.4.3)\n",
            "Installing collected packages: torchbearer\n",
            "Successfully installed torchbearer-0.5.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-xPeofkDXYVk"
      },
      "source": [
        "import torch\n",
        "import torchbearer\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as transforms\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import MNIST\n",
        "import numpy as np\n",
        "import pickle\n",
        "from torchbearer.callbacks import LiveLossPlot\n",
        "from itertools import product\n",
        "import gc\n",
        "from scipy.ndimage import gaussian_filter\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import random\n",
        "import torch.nn.functional as F\n",
        "from torch import nn\n",
        "import sys\n",
        "import torchvision.utils\n",
        "from torchvision import models\n",
        "import torchvision.datasets as dsets\n",
        "import torchvision.transforms as transforms"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KGRop3D5XmRL"
      },
      "source": [
        "# fix random seed for reproducibility\n",
        "seed = 7\n",
        "torch.manual_seed(seed)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "np.random.seed(seed)\n",
        "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\""
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OWmXVQQYXqbF"
      },
      "source": [
        "# flatten 28*28 images to a 784 vector for each image\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),  # convert to tensor\n",
        "    transforms.Lambda(lambda x: x.view(-1))  # flatten into vector\n",
        "])"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PjXtaOt8XtTG"
      },
      "source": [
        "#models\n",
        "#Baseline\n",
        "class BaselineModel(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, num_classes):\n",
        "    super(BaselineModel, self).__init__()\n",
        "    self.fc1 = nn.Linear(input_size, hidden_size) \n",
        "    self.fc2 = nn.Linear(hidden_size, hidden_size) \n",
        "    self.fc3 = nn.Linear(hidden_size, num_classes)  \n",
        "    \n",
        "  def forward(self, x):\n",
        "      out = self.fc1(x)\n",
        "      out = F.relu(out)\n",
        "      out = F.dropout(out, 0.2)        \n",
        "      out = self.fc2(out)        \n",
        "      out = F.relu(out)\n",
        "      out = self.fc3(out)\n",
        "      if not self.training:\n",
        "          out = F.softmax(out, dim=1)\n",
        "      return out\n",
        "\n",
        "#Defensive Distillation\n",
        "class DistillationNetwork(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(DistillationNetwork, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(1, 32, (5, 5), padding=0)\n",
        "    self.conv2 = nn.Conv2d(32, 64, (3, 3), padding=0)\n",
        "    self.fc1 = nn.Linear(64 * 5**2, 1200)\n",
        "    self.fc2 = nn.Linear(1200, 10)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = torch.reshape(x, [-1, 1,28,28])\n",
        "    out = self.conv1(x)\n",
        "    out = F.relu(out)\n",
        "    out = F.max_pool2d(out, (2,2))\n",
        "    out = self.conv2(out)\n",
        "    out = F.relu(out)\n",
        "    out = F.max_pool2d(out, (2,2))\n",
        "    out = F.dropout(out, 0.2)\n",
        "    out = out.view(out.shape[0], -1)\n",
        "    out = self.fc1(out)\n",
        "    out = F.relu(out)\n",
        "    out = self.fc2(out)\n",
        "    if not self.training:\n",
        "      out = F.softmax(out/50, dim=1)  #authors used T=50\n",
        "    return out\n",
        "\n",
        "#Fine-tuning\n",
        "\n",
        "\n",
        "#Control ANN\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}